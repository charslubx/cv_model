#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨ç†åŠŸèƒ½æµ‹è¯•è„šæœ¬

æµ‹è¯•å›¾ç‰‡åŠ è½½ã€é¢„å¤„ç†å’Œæ¨¡å‹æ¨ç†åŠŸèƒ½
"""

import os
import sys
import torch
import logging
from pathlib import Path
from PIL import Image
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from inference import FashionInference
from base_model import FullModel

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def create_dummy_model():
    """åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿæ¨¡å‹ç”¨äºæµ‹è¯•"""
    logger.info("åˆ›å»ºè™šæ‹Ÿæ¨¡å‹ç”¨äºæµ‹è¯•...")
    
    try:
        model = FullModel(
            num_classes=26,
            enable_segmentation=False,
            enable_textile_classification=True,
            num_fabric_classes=20,
            num_fiber_classes=32,
            gat_dims=[512, 256],  # ä½¿ç”¨è¾ƒå°çš„ç»´åº¦
            gat_heads=4
        )
        
        # ä¿å­˜è™šæ‹Ÿæ¨¡å‹
        dummy_model_path = "dummy_model.pth"
        torch.save(model, dummy_model_path)
        logger.info(f"âœ“ è™šæ‹Ÿæ¨¡å‹å·²ä¿å­˜: {dummy_model_path}")
        
        return dummy_model_path
        
    except Exception as e:
        logger.error(f"åˆ›å»ºè™šæ‹Ÿæ¨¡å‹å¤±è´¥: {e}")
        return None


def test_image_loading():
    """æµ‹è¯•å›¾ç‰‡åŠ è½½åŠŸèƒ½"""
    logger.info("æµ‹è¯•å›¾ç‰‡åŠ è½½åŠŸèƒ½...")
    
    # åˆ›å»ºæµ‹è¯•å›¾ç‰‡
    test_image_path = "test_image.jpg"
    
    try:
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•å›¾ç‰‡
        from PIL import Image
        import numpy as np
        
        # åˆ›å»ºéšæœºå›¾ç‰‡
        test_image = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)
        pil_image = Image.fromarray(test_image)
        pil_image.save(test_image_path)
        
        logger.info(f"âœ“ æµ‹è¯•å›¾ç‰‡å·²åˆ›å»º: {test_image_path}")
        
        # æµ‹è¯•å›¾ç‰‡åŠ è½½
        image = Image.open(test_image_path).convert('RGB')
        logger.info(f"âœ“ å›¾ç‰‡åŠ è½½æˆåŠŸ: {image.size}")
        
        return test_image_path
        
    except Exception as e:
        logger.error(f"å›¾ç‰‡åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
        return None


def test_inference_class():
    """æµ‹è¯•æ¨ç†ç±»çš„åŸºæœ¬åŠŸèƒ½"""
    logger.info("æµ‹è¯•æ¨ç†ç±»çš„åŸºæœ¬åŠŸèƒ½...")
    
    # åˆ›å»ºè™šæ‹Ÿæ¨¡å‹
    model_path = create_dummy_model()
    if not model_path:
        logger.error("æ— æ³•åˆ›å»ºè™šæ‹Ÿæ¨¡å‹")
        return False
    
    # åˆ›å»ºæµ‹è¯•å›¾ç‰‡
    image_path = test_image_loading()
    if not image_path:
        logger.error("æ— æ³•åˆ›å»ºæµ‹è¯•å›¾ç‰‡")
        return False
    
    try:
        # åˆ›å»ºæ¨ç†å™¨
        inferencer = FashionInference(model_path)
        logger.info("âœ“ æ¨ç†å™¨åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•å›¾ç‰‡é¢„å¤„ç†
        image_tensor = inferencer.load_image(image_path)
        logger.info(f"âœ“ å›¾ç‰‡é¢„å¤„ç†æˆåŠŸ: {image_tensor.shape}")
        
        # æµ‹è¯•æ¨ç†
        results = inferencer.predict(image_path)
        logger.info("âœ“ æ¨ç†æˆåŠŸ")
        
        # æ£€æŸ¥ç»“æœç»“æ„
        expected_keys = ['raw_outputs', 'predictions', 'probabilities', 'top_predictions']
        for key in expected_keys:
            if key in results:
                logger.info(f"  âœ“ ç»“æœåŒ…å« {key}")
            else:
                logger.warning(f"  âœ— ç»“æœç¼ºå°‘ {key}")
        
        # æ ¼å¼åŒ–è¾“å‡º
        formatted = inferencer.format_results(results)
        logger.info("âœ“ ç»“æœæ ¼å¼åŒ–æˆåŠŸ")
        print("\n" + "="*50)
        print("æµ‹è¯•æ¨ç†ç»“æœ:")
        print(formatted)
        print("="*50)
        
        return True
        
    except Exception as e:
        logger.error(f"æ¨ç†ç±»æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        for file_path in [model_path, image_path]:
            if file_path and os.path.exists(file_path):
                try:
                    os.remove(file_path)
                    logger.info(f"âœ“ å·²æ¸…ç†æµ‹è¯•æ–‡ä»¶: {file_path}")
                except:
                    pass


def test_real_data():
    """æµ‹è¯•çœŸå®æ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰"""
    logger.info("æµ‹è¯•çœŸå®æ•°æ®...")
    
    # å¯»æ‰¾çœŸå®å›¾ç‰‡
    test_dirs = [
        "/home/cv_model/fabric/train",
        "/home/cv_model/fiber/train"
    ]
    
    real_images = []
    for test_dir in test_dirs:
        if os.path.exists(test_dir):
            for class_dir in os.listdir(test_dir)[:2]:  # å–å‰2ä¸ªç±»åˆ«
                class_path = os.path.join(test_dir, class_dir)
                if os.path.isdir(class_path):
                    images = [f for f in os.listdir(class_path) 
                            if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
                    if images:
                        real_images.append(os.path.join(class_path, images[0]))
                        break
    
    if not real_images:
        logger.warning("æ²¡æœ‰æ‰¾åˆ°çœŸå®å›¾ç‰‡ï¼Œè·³è¿‡çœŸå®æ•°æ®æµ‹è¯•")
        return True
    
    logger.info(f"æ‰¾åˆ° {len(real_images)} å¼ çœŸå®å›¾ç‰‡")
    
    # åˆ›å»ºè™šæ‹Ÿæ¨¡å‹è¿›è¡Œæµ‹è¯•
    model_path = create_dummy_model()
    if not model_path:
        logger.error("æ— æ³•åˆ›å»ºè™šæ‹Ÿæ¨¡å‹")
        return False
    
    try:
        # åˆ›å»ºæ¨ç†å™¨
        inferencer = FashionInference(model_path)
        
        # æµ‹è¯•çœŸå®å›¾ç‰‡
        for i, image_path in enumerate(real_images[:3]):  # åªæµ‹è¯•å‰3å¼ 
            logger.info(f"æµ‹è¯•çœŸå®å›¾ç‰‡ {i+1}: {image_path}")
            
            try:
                results = inferencer.predict(image_path)
                logger.info(f"âœ“ çœŸå®å›¾ç‰‡ {i+1} æ¨ç†æˆåŠŸ")
                
                # æ˜¾ç¤ºç®€åŒ–ç»“æœ
                if 'predictions' in results:
                    for task, pred in results['predictions'].items():
                        if pred:
                            logger.info(f"  {task}: {pred}")
                
            except Exception as e:
                logger.error(f"çœŸå®å›¾ç‰‡ {i+1} æ¨ç†å¤±è´¥: {e}")
        
        return True
        
    except Exception as e:
        logger.error(f"çœŸå®æ•°æ®æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    finally:
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        if model_path and os.path.exists(model_path):
            try:
                os.remove(model_path)
            except:
                pass


def test_batch_inference():
    """æµ‹è¯•æ‰¹é‡æ¨ç†"""
    logger.info("æµ‹è¯•æ‰¹é‡æ¨ç†...")
    
    # åˆ›å»ºå¤šä¸ªæµ‹è¯•å›¾ç‰‡
    test_images = []
    for i in range(3):
        image_path = f"test_batch_{i}.jpg"
        try:
            # åˆ›å»ºéšæœºå›¾ç‰‡
            test_image = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)
            pil_image = Image.fromarray(test_image)
            pil_image.save(image_path)
            test_images.append(image_path)
        except Exception as e:
            logger.error(f"åˆ›å»ºæµ‹è¯•å›¾ç‰‡ {i} å¤±è´¥: {e}")
    
    if not test_images:
        logger.error("æ— æ³•åˆ›å»ºæµ‹è¯•å›¾ç‰‡")
        return False
    
    # åˆ›å»ºè™šæ‹Ÿæ¨¡å‹
    model_path = create_dummy_model()
    if not model_path:
        logger.error("æ— æ³•åˆ›å»ºè™šæ‹Ÿæ¨¡å‹")
        return False
    
    try:
        # åˆ›å»ºæ¨ç†å™¨
        inferencer = FashionInference(model_path)
        
        # æ‰¹é‡æ¨ç†
        batch_results = inferencer.predict_batch(test_images)
        logger.info(f"âœ“ æ‰¹é‡æ¨ç†æˆåŠŸ: {len(batch_results)} ä¸ªç»“æœ")
        
        # æ£€æŸ¥ç»“æœ
        for i, result in enumerate(batch_results):
            if 'error' in result:
                logger.error(f"æ‰¹é‡ç»“æœ {i} æœ‰é”™è¯¯: {result['error']}")
            else:
                logger.info(f"âœ“ æ‰¹é‡ç»“æœ {i} æ­£å¸¸")
        
        return True
        
    except Exception as e:
        logger.error(f"æ‰¹é‡æ¨ç†æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    finally:
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        for file_path in test_images + [model_path]:
            if file_path and os.path.exists(file_path):
                try:
                    os.remove(file_path)
                except:
                    pass


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("å¼€å§‹æ¨ç†åŠŸèƒ½æµ‹è¯•...")
    logger.info("=" * 60)
    
    test_results = []
    
    # 1. æµ‹è¯•æ¨ç†ç±»åŸºæœ¬åŠŸèƒ½
    logger.info("1. æµ‹è¯•æ¨ç†ç±»åŸºæœ¬åŠŸèƒ½")
    result1 = test_inference_class()
    test_results.append(("æ¨ç†ç±»åŸºæœ¬åŠŸèƒ½", result1))
    logger.info("=" * 60)
    
    # 2. æµ‹è¯•çœŸå®æ•°æ®
    logger.info("2. æµ‹è¯•çœŸå®æ•°æ®")
    result2 = test_real_data()
    test_results.append(("çœŸå®æ•°æ®æµ‹è¯•", result2))
    logger.info("=" * 60)
    
    # 3. æµ‹è¯•æ‰¹é‡æ¨ç†
    logger.info("3. æµ‹è¯•æ‰¹é‡æ¨ç†")
    result3 = test_batch_inference()
    test_results.append(("æ‰¹é‡æ¨ç†æµ‹è¯•", result3))
    logger.info("=" * 60)
    
    # æ€»ç»“
    logger.info("æµ‹è¯•æ€»ç»“:")
    all_passed = True
    for test_name, result in test_results:
        status = "âœ“ é€šè¿‡" if result else "âœ— å¤±è´¥"
        logger.info(f"  {test_name}: {status}")
        if not result:
            all_passed = False
    
    if all_passed:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ¨ç†åŠŸèƒ½æ­£å¸¸ã€‚")
        return True
    else:
        logger.warning("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚")
        return False


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
