# å›¾ç‰‡æ¨ç†ä½¿ç”¨æŒ‡å—

æœ¬æŒ‡å—ä»‹ç»å¦‚ä½•ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹å›¾ç‰‡è¿›è¡Œåˆ†ç±»æ¨ç†ï¼Œè¾“å‡ºå¯¹åº”çš„ç±»å‹ç»“æœã€‚

## åŠŸèƒ½æ¦‚è¿°

æ¨ç†ç³»ç»Ÿæ”¯æŒä»¥ä¸‹åŠŸèƒ½ï¼š
1. **å›¾ç‰‡åŠ è½½å’Œé¢„å¤„ç†**ï¼šè‡ªåŠ¨å¤„ç†å„ç§æ ¼å¼çš„å›¾ç‰‡
2. **å¤šä»»åŠ¡é¢„æµ‹**ï¼šåŒæ—¶è¾“å‡ºDeepFashionå±æ€§ã€Fabricç±»å‹ã€Fiberç±»å‹
3. **æ‰¹é‡å¤„ç†**ï¼šæ”¯æŒæ‰¹é‡å¤„ç†å¤šå¼ å›¾ç‰‡
4. **ç»“æœæ ¼å¼åŒ–**ï¼šæä¾›æ˜“è¯»çš„ç»“æœè¾“å‡ºæ ¼å¼
5. **ç½®ä¿¡åº¦è¯„ä¼°**ï¼šä¸ºæ¯ä¸ªé¢„æµ‹æä¾›ç½®ä¿¡åº¦åˆ†æ•°

## æ–‡ä»¶è¯´æ˜

### æ ¸å¿ƒæ–‡ä»¶
- **`inference.py`**: ä¸»è¦çš„æ¨ç†ç±»å’ŒåŠŸèƒ½å®ç°
- **`demo_inference.py`**: å‘½ä»¤è¡Œæ¼”ç¤ºè„šæœ¬
- **`test_inference.py`**: æ¨ç†åŠŸèƒ½æµ‹è¯•è„šæœ¬

### æ¨ç†ç±» `FashionInference`

ä¸»è¦æ–¹æ³•ï¼š
- `__init__(model_path, device)`: åˆå§‹åŒ–æ¨ç†å™¨
- `predict(image_input)`: å•å¼ å›¾ç‰‡æ¨ç†
- `predict_batch(image_paths)`: æ‰¹é‡å›¾ç‰‡æ¨ç†
- `format_results(results, detailed)`: æ ¼å¼åŒ–ç»“æœè¾“å‡º

## ä½¿ç”¨æ–¹æ³•

### 1. åŸºæœ¬ä½¿ç”¨

```python
from inference import FashionInference

# åˆ›å»ºæ¨ç†å™¨
inferencer = FashionInference("mixed_checkpoints/best_model.pth")

# å•å¼ å›¾ç‰‡æ¨ç†
results = inferencer.predict("path/to/image.jpg")

# æ ¼å¼åŒ–è¾“å‡º
formatted = inferencer.format_results(results, detailed=True)
print(formatted)
```

### 2. å‘½ä»¤è¡Œä½¿ç”¨

#### å•å¼ å›¾ç‰‡æ¨ç†
```bash
python demo_inference.py --image path/to/image.jpg --detailed
```

#### æ‰¹é‡å›¾ç‰‡æ¨ç†
```bash
python demo_inference.py --batch image1.jpg image2.jpg image3.jpg
```

#### è‡ªåŠ¨å¯»æ‰¾æµ‹è¯•å›¾ç‰‡
```bash
python demo_inference.py --auto-find --detailed
```

#### ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
```bash
python demo_inference.py --auto-find --output results.json
```

### 3. æ‰¹é‡å¤„ç†

```python
# æ‰¹é‡å¤„ç†å¤šå¼ å›¾ç‰‡
image_paths = ["img1.jpg", "img2.jpg", "img3.jpg"]
batch_results = inferencer.predict_batch(image_paths)

for result in batch_results:
    if 'error' not in result:
        print(f"å›¾ç‰‡: {result['image_path']}")
        formatted = inferencer.format_results(result)
        print(formatted)
```

## è¾“å‡ºç»“æœè¯´æ˜

### ç»“æœç»“æ„

æ¨ç†ç»“æœåŒ…å«ä»¥ä¸‹ä¸»è¦éƒ¨åˆ†ï¼š

```python
{
    'raw_outputs': {          # åŸå§‹æ¨¡å‹è¾“å‡º
        'deepfashion_attrs': tensor,
        'fabric': tensor,
        'fiber': tensor,
        'textile': tensor
    },
    'predictions': {          # è§£æåçš„é¢„æµ‹ç»“æœ
        'deepfashion_attrs': [...],
        'fabric': {...},
        'fiber': {...},
        'textile': {...}
    },
    'probabilities': {        # æ¦‚ç‡åˆ†å¸ƒ
        'deepfashion_attrs': tensor,
        'fabric': tensor,
        'fiber': tensor
    },
    'top_predictions': {      # Top-Ké¢„æµ‹
        'fabric': [...],
        'fiber': [...]
    }
}
```

### 1. DeepFashionå±æ€§é¢„æµ‹

è¾“å‡ºæ¿€æ´»çš„å±æ€§åŠå…¶ç½®ä¿¡åº¦ï¼š

```python
'deepfashion_attrs': [
    {'attribute': 'texture_1', 'confidence': 0.85},
    {'attribute': 'fabric_2', 'confidence': 0.72},
    {'attribute': 'style_3', 'confidence': 0.68}
]
```

### 2. Fabricé¢æ–™é¢„æµ‹

è¾“å‡ºæœ€å¯èƒ½çš„é¢æ–™ç±»å‹ï¼š

```python
'fabric': {
    'class': 'denim',
    'confidence': 0.92
}
```

Top-5é¢„æµ‹ï¼š
```python
'fabric': [
    {'class': 'denim', 'confidence': 0.92},
    {'class': 'canvas', 'confidence': 0.05},
    {'class': 'twill', 'confidence': 0.02}
]
```

### 3. Fiberçº¤ç»´é¢„æµ‹

è¾“å‡ºæœ€å¯èƒ½çš„çº¤ç»´ç±»å‹ï¼š

```python
'fiber': {
    'class': 'cotton',
    'confidence': 0.88
}
```

### 4. åˆ†å‰²ç»“æœï¼ˆå¦‚æœå¯ç”¨ï¼‰

```python
'segmentation': {
    'mask': numpy_array,      # åˆ†å‰²æ©ç 
    'coverage': 0.75          # è¦†ç›–ç‡
}
```

## æ ¼å¼åŒ–è¾“å‡ºç¤ºä¾‹

```
============================================================
å›¾ç‰‡åˆ†ç±»ç»“æœ
============================================================

ğŸ“‹ DeepFashionå±æ€§ (5ä¸ª):
  â€¢ texture_1: 0.850
  â€¢ fabric_2: 0.720
  â€¢ style_3: 0.680
  â€¢ part_1: 0.650
  â€¢ shape_2: 0.620

ğŸ§µ é¢æ–™ç±»å‹:
  â€¢ denim: 0.920
  Top-5é¢„æµ‹:
    - denim: 0.920
    - canvas: 0.050
    - twill: 0.020
    - corduroy: 0.008
    - flannel: 0.002

ğŸ§¶ çº¤ç»´ç±»å‹:
  â€¢ cotton: 0.880
  Top-5é¢„æµ‹:
    - cotton: 0.880
    - polyester: 0.080
    - wool: 0.025
    - silk: 0.010
    - nylon: 0.005

âœ‚ï¸ åˆ†å‰²ç»“æœ:
  â€¢ è¦†ç›–ç‡: 0.750

============================================================
```

## æ”¯æŒçš„å›¾ç‰‡æ ¼å¼

- JPEG (.jpg, .jpeg)
- PNG (.png)
- BMP (.bmp)
- TIFF (.tiff)
- WebP (.webp)

## é¢„å¤„ç†æ­¥éª¤

1. **å°ºå¯¸è°ƒæ•´**: è°ƒæ•´åˆ°224x224åƒç´ 
2. **æ ¼å¼è½¬æ¢**: è½¬æ¢ä¸ºRGBæ ¼å¼
3. **å¼ é‡åŒ–**: è½¬æ¢ä¸ºPyTorchå¼ é‡
4. **æ ‡å‡†åŒ–**: ä½¿ç”¨ImageNetæ ‡å‡†åŒ–å‚æ•°
5. **è®¾å¤‡è½¬ç§»**: ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡ï¼ˆCPU/GPUï¼‰

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. GPUåŠ é€Ÿ
```python
# ä½¿ç”¨GPUæ¨ç†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
inferencer = FashionInference(model_path, device="cuda")
```

### 2. æ‰¹é‡å¤„ç†
```python
# æ‰¹é‡å¤„ç†æ¯”å•å¼ å¤„ç†æ›´é«˜æ•ˆ
batch_results = inferencer.predict_batch(image_paths)
```

### 3. æ¨¡å‹ä¼˜åŒ–
```python
# å¯ä»¥è€ƒè™‘æ¨¡å‹é‡åŒ–æˆ–å…¶ä»–ä¼˜åŒ–æŠ€æœ¯
# è¿™éœ€è¦åœ¨æ¨¡å‹è®­ç»ƒæˆ–ä¿å­˜æ—¶è¿›è¡Œ
```

## é”™è¯¯å¤„ç†

### å¸¸è§é”™è¯¯åŠè§£å†³æ–¹æ¡ˆ

1. **æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨**
   ```
   é”™è¯¯: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: path/to/model.pth
   è§£å†³: æ£€æŸ¥æ¨¡å‹è·¯å¾„ï¼Œç¡®ä¿å·²å®Œæˆè®­ç»ƒ
   ```

2. **å›¾ç‰‡æ–‡ä»¶æŸå**
   ```
   é”™è¯¯: å›¾ç‰‡åŠ è½½å¤±è´¥
   è§£å†³: æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶æ˜¯å¦å®Œæ•´ï¼Œæ ¼å¼æ˜¯å¦æ”¯æŒ
   ```

3. **å†…å­˜ä¸è¶³**
   ```
   é”™è¯¯: CUDA out of memory
   è§£å†³: ä½¿ç”¨CPUæ¨ç†æˆ–å‡å°‘æ‰¹é‡å¤§å°
   ```

4. **ç±»åˆ«ä¿¡æ¯ç¼ºå¤±**
   ```
   è­¦å‘Š: æ— æ³•åŠ è½½ç±»åˆ«ä¿¡æ¯
   è§£å†³: ç¡®ä¿æ•°æ®é›†ç›®å½•ç»“æ„æ­£ç¡®
   ```

## æµ‹è¯•å’ŒéªŒè¯

### è¿è¡Œæµ‹è¯•
```bash
# è¿è¡Œå®Œæ•´æµ‹è¯•
python test_inference.py

# è¿è¡Œæ¼”ç¤º
python demo_inference.py --auto-find
```

### éªŒè¯ç»“æœ
1. æ£€æŸ¥è¾“å‡ºæ ¼å¼æ˜¯å¦æ­£ç¡®
2. éªŒè¯ç½®ä¿¡åº¦åˆ†æ•°æ˜¯å¦åˆç†
3. ç¡®è®¤ç±»åˆ«é¢„æµ‹æ˜¯å¦ç¬¦åˆé¢„æœŸ
4. æµ‹è¯•æ‰¹é‡å¤„ç†åŠŸèƒ½

## é›†æˆåˆ°å…¶ä»–é¡¹ç›®

### ä½œä¸ºæ¨¡å—ä½¿ç”¨
```python
import sys
sys.path.append('/path/to/cv_model')

from inference import FashionInference

# åœ¨ä½ çš„é¡¹ç›®ä¸­ä½¿ç”¨
inferencer = FashionInference("model.pth")
results = inferencer.predict("image.jpg")
```

### APIå°è£…ç¤ºä¾‹
```python
from flask import Flask, request, jsonify
from inference import FashionInference

app = Flask(__name__)
inferencer = FashionInference("model.pth")

@app.route('/predict', methods=['POST'])
def predict():
    if 'image' not in request.files:
        return jsonify({'error': 'No image provided'}), 400
    
    image_file = request.files['image']
    # ä¿å­˜ä¸´æ—¶æ–‡ä»¶å¹¶æ¨ç†
    # ... å¤„ç†é€»è¾‘ ...
    
    results = inferencer.predict(temp_path)
    return jsonify(results['predictions'])
```

## æ³¨æ„äº‹é¡¹

1. **æ¨¡å‹å…¼å®¹æ€§**: ç¡®ä¿ä½¿ç”¨çš„æ¨¡å‹ä¸å½“å‰ä»£ç ç‰ˆæœ¬å…¼å®¹
2. **è®¾å¤‡å†…å­˜**: å¤§æ¨¡å‹å¯èƒ½éœ€è¦å¤§é‡GPUå†…å­˜
3. **å›¾ç‰‡è´¨é‡**: å›¾ç‰‡è´¨é‡ä¼šå½±å“é¢„æµ‹å‡†ç¡®æ€§
4. **ç±»åˆ«æ˜ å°„**: ç¡®ä¿ç±»åˆ«åç§°æ˜ å°„æ­£ç¡®
5. **ç‰ˆæœ¬ä¾èµ–**: æ³¨æ„PyTorchå’Œå…¶ä»–ä¾èµ–çš„ç‰ˆæœ¬å…¼å®¹æ€§

é€šè¿‡è¿™ä¸ªæ¨ç†ç³»ç»Ÿï¼Œæ‚¨å¯ä»¥è½»æ¾åœ°å°†è®­ç»ƒå¥½çš„æ¨¡å‹åº”ç”¨åˆ°å®é™…çš„å›¾ç‰‡åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œè·å¾—å‡†ç¡®çš„ç±»å‹é¢„æµ‹ç»“æœã€‚
