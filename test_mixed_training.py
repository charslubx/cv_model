#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ··åˆè®­ç»ƒç³»ç»Ÿæµ‹è¯•è„šæœ¬

æµ‹è¯•TextileNetæ•°æ®é›†åŠ è½½å’Œæ··åˆæ•°æ®é›†åŠŸèƒ½
"""

import os
import torch
import logging
from pathlib import Path
from torchvision import transforms

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å¯¼å…¥æˆ‘ä»¬çš„æ¨¡å—
from training import TextileNetDataset, MixedDataset, get_transforms
from base_model import FullModel


def test_textile_dataset():
    """æµ‹è¯•TextileNetæ•°æ®é›†åŠ è½½"""
    logger.info("æµ‹è¯•TextileNetæ•°æ®é›†åŠ è½½...")
    
    textile_root = "/home/cv_model"
    transform = get_transforms(train=True)
    
    # æµ‹è¯•Fabricæ•°æ®é›†
    try:
        fabric_dataset = TextileNetDataset(
            root_dir=textile_root,
            dataset_type='fabric',
            split='train',
            transform=transform
        )
        logger.info(f"âœ“ Fabricæ•°æ®é›†åŠ è½½æˆåŠŸ: {len(fabric_dataset)} æ ·æœ¬")
        logger.info(f"  ç±»åˆ«æ•°: {fabric_dataset.get_num_classes()}")
        logger.info(f"  ç±»åˆ«å: {fabric_dataset.get_class_names()[:5]}...")  # æ˜¾ç¤ºå‰5ä¸ªç±»åˆ«
        
        # æµ‹è¯•è·å–æ ·æœ¬
        sample = fabric_dataset[0]
        logger.info(f"  æ ·æœ¬é”®: {list(sample.keys())}")
        logger.info(f"  å›¾åƒå½¢çŠ¶: {sample['image'].shape}")
        
    except Exception as e:
        logger.error(f"âœ— Fabricæ•°æ®é›†åŠ è½½å¤±è´¥: {e}")
    
    # æµ‹è¯•Fiberæ•°æ®é›†
    try:
        fiber_dataset = TextileNetDataset(
            root_dir=textile_root,
            dataset_type='fiber',
            split='train',
            transform=transform
        )
        logger.info(f"âœ“ Fiberæ•°æ®é›†åŠ è½½æˆåŠŸ: {len(fiber_dataset)} æ ·æœ¬")
        logger.info(f"  ç±»åˆ«æ•°: {fiber_dataset.get_num_classes()}")
        logger.info(f"  ç±»åˆ«å: {fiber_dataset.get_class_names()[:5]}...")  # æ˜¾ç¤ºå‰5ä¸ªç±»åˆ«
        
        # æµ‹è¯•è·å–æ ·æœ¬
        sample = fiber_dataset[0]
        logger.info(f"  æ ·æœ¬é”®: {list(sample.keys())}")
        logger.info(f"  å›¾åƒå½¢çŠ¶: {sample['image'].shape}")
        
        return fabric_dataset, fiber_dataset
        
    except Exception as e:
        logger.error(f"âœ— Fiberæ•°æ®é›†åŠ è½½å¤±è´¥: {e}")
        return None, None


def test_mixed_dataset(fabric_dataset, fiber_dataset):
    """æµ‹è¯•æ··åˆæ•°æ®é›†"""
    if fabric_dataset is None or fiber_dataset is None:
        logger.warning("è·³è¿‡æ··åˆæ•°æ®é›†æµ‹è¯•ï¼ˆç¼ºå°‘åŸºç¡€æ•°æ®é›†ï¼‰")
        return None
    
    logger.info("æµ‹è¯•æ··åˆæ•°æ®é›†...")
    
    try:
        mixed_dataset = MixedDataset(
            deepfashion_dataset=None,  # æš‚æ—¶ä¸ä½¿ç”¨DeepFashion
            fabric_dataset=fabric_dataset,
            fiber_dataset=fiber_dataset,
            mixing_strategy='balanced',
            deepfashion_weight=0.0,
            fabric_weight=0.5,
            fiber_weight=0.5
        )
        
        logger.info(f"âœ“ æ··åˆæ•°æ®é›†åˆ›å»ºæˆåŠŸ: {len(mixed_dataset)} æ ·æœ¬")
        
        # è·å–æ•°æ®é›†ä¿¡æ¯
        info = mixed_dataset.get_dataset_info()
        logger.info("æ•°æ®é›†ä¿¡æ¯:")
        for name, dataset_info in info['datasets'].items():
            logger.info(f"  {name}: {dataset_info}")
        
        # æµ‹è¯•è·å–æ ·æœ¬
        sample = mixed_dataset[0]
        logger.info(f"æ ·æœ¬é”®: {list(sample.keys())}")
        logger.info(f"æ¥æºæ•°æ®é›†: {sample.get('source_dataset')}")
        logger.info(f"å›¾åƒå½¢çŠ¶: {sample['image'].shape}")
        
        return mixed_dataset
        
    except Exception as e:
        logger.error(f"âœ— æ··åˆæ•°æ®é›†åˆ›å»ºå¤±è´¥: {e}")
        return None


def test_model(fabric_dataset, fiber_dataset):
    """æµ‹è¯•å¢å¼ºæ¨¡å‹"""
    logger.info("æµ‹è¯•å¢å¼ºæ¨¡å‹...")
    
    try:
        # è·å–ç±»åˆ«æ•°é‡
        num_fabric_classes = fabric_dataset.get_num_classes() if fabric_dataset else 20
        num_fiber_classes = fiber_dataset.get_num_classes() if fiber_dataset else 32
        
        # åˆ›å»ºæ¨¡å‹
        model = FullModel(
            num_classes=26,
            enable_segmentation=False,
            enable_textile_classification=True,
            num_fabric_classes=num_fabric_classes,
            num_fiber_classes=num_fiber_classes,
            gat_dims=[512, 256],  # ä½¿ç”¨è¾ƒå°çš„ç»´åº¦è¿›è¡Œæµ‹è¯•
            gat_heads=4
        )
        
        logger.info(f"âœ“ æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        logger.info(f"  å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        batch_size = 2
        test_input = torch.randn(batch_size, 3, 224, 224)
        
        model.eval()
        with torch.no_grad():
            outputs = model(test_input)
        
        logger.info("æ¨¡å‹è¾“å‡º:")
        for key, value in outputs.items():
            if isinstance(value, torch.Tensor):
                logger.info(f"  {key}: {value.shape}")
        
        # éªŒè¯è¾“å‡ºç»´åº¦
        expected_shapes = {
            'attr_logits': (batch_size, 26),
            'fabric_logits': (batch_size, num_fabric_classes),
            'fiber_logits': (batch_size, num_fiber_classes),
            'textile_logits': (batch_size, max(num_fabric_classes, num_fiber_classes))
        }
        
        for key, expected_shape in expected_shapes.items():
            if key in outputs:
                actual_shape = outputs[key].shape
                if actual_shape == expected_shape:
                    logger.info(f"  âœ“ {key} å½¢çŠ¶æ­£ç¡®: {actual_shape}")
                else:
                    logger.error(f"  âœ— {key} å½¢çŠ¶é”™è¯¯: æœŸæœ› {expected_shape}, å®é™… {actual_shape}")
        
        return model
        
    except Exception as e:
        logger.error(f"âœ— æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def test_data_paths():
    """æµ‹è¯•æ•°æ®è·¯å¾„"""
    logger.info("æ£€æŸ¥æ•°æ®è·¯å¾„...")
    
    paths_to_check = [
        "/home/cv_model/fabric/train",
        "/home/cv_model/fiber/train",
        "/home/cv_model/DeepFashion"
    ]
    
    for path in paths_to_check:
        if os.path.exists(path):
            logger.info(f"âœ“ è·¯å¾„å­˜åœ¨: {path}")
            if os.path.isdir(path):
                try:
                    contents = os.listdir(path)
                    logger.info(f"  åŒ…å« {len(contents)} ä¸ªé¡¹ç›®")
                    if contents:
                        logger.info(f"  ç¤ºä¾‹å†…å®¹: {contents[:3]}...")
                except PermissionError:
                    logger.warning(f"  æ— æ³•è¯»å–ç›®å½•å†…å®¹ï¼ˆæƒé™ä¸è¶³ï¼‰")
        else:
            logger.warning(f"âœ— è·¯å¾„ä¸å­˜åœ¨: {path}")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("å¼€å§‹æ··åˆè®­ç»ƒç³»ç»Ÿæµ‹è¯•...")
    logger.info("=" * 50)
    
    # 1. æµ‹è¯•æ•°æ®è·¯å¾„
    test_data_paths()
    logger.info("=" * 50)
    
    # 2. æµ‹è¯•TextileNetæ•°æ®é›†
    fabric_dataset, fiber_dataset = test_textile_dataset()
    logger.info("=" * 50)
    
    # 3. æµ‹è¯•æ··åˆæ•°æ®é›†
    mixed_dataset = test_mixed_dataset(fabric_dataset, fiber_dataset)
    logger.info("=" * 50)
    
    # 4. æµ‹è¯•æ¨¡å‹
    model = test_model(fabric_dataset, fiber_dataset)
    logger.info("=" * 50)
    
    # 5. æ€»ç»“
    logger.info("æµ‹è¯•æ€»ç»“:")
    logger.info(f"  TextileNetæ•°æ®é›†: {'âœ“' if fabric_dataset and fiber_dataset else 'âœ—'}")
    logger.info(f"  æ··åˆæ•°æ®é›†: {'âœ“' if mixed_dataset else 'âœ—'}")
    logger.info(f"  å¢å¼ºæ¨¡å‹: {'âœ“' if model else 'âœ—'}")
    
    if fabric_dataset and fiber_dataset and mixed_dataset and model:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿå‡†å¤‡å°±ç»ªã€‚")
        return True
    else:
        logger.warning("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚")
        return False


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
