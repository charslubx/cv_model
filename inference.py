#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å›¾ç‰‡æ¨ç†è„šæœ¬
æ”¯æŒè¯»å–å›¾ç‰‡å¹¶è¾“å‡ºå¯¹åº”çš„ç±»å‹åˆ†ç±»ç»“æœ

åŠŸèƒ½ï¼š
1. åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
2. è¯»å–å’Œé¢„å¤„ç†å›¾ç‰‡
3. è¿›è¡Œæ¨ç†é¢„æµ‹
4. è¾“å‡ºå„ç§ç±»å‹çš„åˆ†ç±»ç»“æœ

ä½œè€…: AI Assistant
æ—¥æœŸ: 2025-10-23
"""

import os
import sys
import torch
import numpy as np
import logging
from pathlib import Path
from PIL import Image
import torch.nn.functional as F
from torchvision import transforms
from typing import Dict, List, Tuple, Optional, Union

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from base_model import FullModel
from training import TextileNetDataset

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class FashionInference:
    """æœè£…å›¾ç‰‡æ¨ç†ç±»"""
    
    # DeepFashionå±æ€§æ ‡ç­¾æ˜ å°„
    DEEPFASHION_ATTRIBUTES = {
        0: "floral",           # èŠ±å‰å›¾æ¡ˆ
        1: "graphic",          # å›¾å½¢å›¾æ¡ˆ  
        2: "striped",          # æ¡çº¹
        3: "embroidered",      # åˆºç»£
        4: "pleated",          # è¤¶çš±
        5: "solid",            # çº¯è‰²
        6: "lattice",          # æ ¼å­
        7: "long_sleeve",      # é•¿è¢–
        8: "short_sleeve",     # çŸ­è¢–
        9: "sleeveless",       # æ— è¢–
        10: "maxi_length",     # é•¿æ¬¾
        11: "mini_length",     # çŸ­æ¬¾
        12: "no_dress",        # éè¿è¡£è£™
        13: "crew_neckline",   # åœ†é¢†
        14: "v_neckline",      # Vé¢†
        15: "square_neckline", # æ–¹é¢†
        16: "no_neckline",     # æ— é¢†
        17: "denim",           # ç‰›ä»”
        18: "chiffon",         # é›ªçºº
        19: "cotton",          # æ£‰è´¨
        20: "leather",         # çš®é©
        21: "faux",            # äººé€ 
        22: "knit",            # é’ˆç»‡
        23: "tight",           # ç´§èº«
        24: "loose",           # å®½æ¾
        25: "conventional"     # å¸¸è§„
    }
    
    # å±æ€§ç±»åˆ«æ˜ å°„
    ATTRIBUTE_CATEGORIES = {
        "pattern": [0, 1, 2, 3, 4, 5, 6],        # å›¾æ¡ˆç±»å‹
        "sleeve": [7, 8, 9],                      # è¢–å­ç±»å‹
        "length": [10, 11, 12],                   # é•¿åº¦ç±»å‹
        "neckline": [13, 14, 15, 16],            # é¢†å£ç±»å‹
        "material": [17, 18, 19, 20, 21, 22],    # æè´¨ç±»å‹
        "fit": [23, 24, 25]                       # ç‰ˆå‹ç±»å‹
    }
    
    def __init__(self, 
                 model_path: str,
                 device: str = "cuda" if torch.cuda.is_available() else "cpu"):
        """åˆå§‹åŒ–æ¨ç†å™¨
        
        Args:
            model_path: è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„
            device: æ¨ç†è®¾å¤‡
        """
        self.device = device
        self.model = None
        self.transform = None
        
        # ç±»åˆ«æ˜ å°„å­—å…¸
        self.fabric_classes = []
        self.fiber_classes = []
        self.deepfashion_attrs = []
        
        # åŠ è½½æ¨¡å‹
        self.load_model(model_path)
        
        # è®¾ç½®å›¾ç‰‡é¢„å¤„ç†
        self.setup_transform()
        
        # åŠ è½½ç±»åˆ«ä¿¡æ¯
        self.load_class_info()
    
    def load_model(self, model_path: str):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        try:
            logger.info(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}")
            
            if not os.path.exists(model_path):
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            
            # åŠ è½½å®Œæ•´æ¨¡å‹
            self.model = torch.load(model_path, map_location=self.device)
            self.model.eval()
            
            logger.info("âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ")
            logger.info(f"  è®¾å¤‡: {self.device}")
            logger.info(f"  å‚æ•°æ•°é‡: {sum(p.numel() for p in self.model.parameters()):,}")
            
        except Exception as e:
            logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def setup_transform(self):
        """è®¾ç½®å›¾ç‰‡é¢„å¤„ç†"""
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        logger.info("âœ“ å›¾ç‰‡é¢„å¤„ç†è®¾ç½®å®Œæˆ")
    
    def load_class_info(self):
        """åŠ è½½ç±»åˆ«ä¿¡æ¯"""
        try:
            # å°è¯•ä»æ•°æ®é›†ä¸­è·å–ç±»åˆ«ä¿¡æ¯
            textile_root = "/home/cv_model"
            
            # åŠ è½½Fabricç±»åˆ«
            if os.path.exists(os.path.join(textile_root, "fabric", "train")):
                try:
                    fabric_dataset = TextileNetDataset(
                        root_dir=textile_root,
                        dataset_type='fabric',
                        split='train',
                        transform=None
                    )
                    self.fabric_classes = fabric_dataset.get_class_names()
                    logger.info(f"âœ“ åŠ è½½Fabricç±»åˆ«: {len(self.fabric_classes)}ä¸ª")
                except Exception as e:
                    logger.warning(f"æ— æ³•åŠ è½½Fabricç±»åˆ«: {e}")
                    self.fabric_classes = [f"fabric_class_{i}" for i in range(20)]
            
            # åŠ è½½Fiberç±»åˆ«
            if os.path.exists(os.path.join(textile_root, "fiber", "train")):
                try:
                    fiber_dataset = TextileNetDataset(
                        root_dir=textile_root,
                        dataset_type='fiber',
                        split='train',
                        transform=None
                    )
                    self.fiber_classes = fiber_dataset.get_class_names()
                    logger.info(f"âœ“ åŠ è½½Fiberç±»åˆ«: {len(self.fiber_classes)}ä¸ª")
                except Exception as e:
                    logger.warning(f"æ— æ³•åŠ è½½Fiberç±»åˆ«: {e}")
                    self.fiber_classes = [f"fiber_class_{i}" for i in range(32)]
            
            # DeepFashionå±æ€§ï¼ˆç¤ºä¾‹ï¼‰
            self.deepfashion_attrs = [
                "texture_1", "texture_2", "texture_3", "texture_4", "texture_5",
                "fabric_1", "fabric_2", "fabric_3", "fabric_4", "fabric_5",
                "shape_1", "shape_2", "shape_3", "shape_4", "shape_5",
                "part_1", "part_2", "part_3", "part_4", "part_5",
                "style_1", "style_2", "style_3", "style_4", "style_5",
                "fit_1"
            ]
            
            logger.info(f"âœ“ ç±»åˆ«ä¿¡æ¯åŠ è½½å®Œæˆ")
            logger.info(f"  DeepFashionå±æ€§: {len(self.deepfashion_attrs)}ä¸ª")
            logger.info(f"  Fabricç±»åˆ«: {len(self.fabric_classes)}ä¸ª")
            logger.info(f"  Fiberç±»åˆ«: {len(self.fiber_classes)}ä¸ª")
            
        except Exception as e:
            logger.warning(f"ç±»åˆ«ä¿¡æ¯åŠ è½½å¤±è´¥: {e}")
    
    def load_image(self, image_path: str) -> torch.Tensor:
        """åŠ è½½å’Œé¢„å¤„ç†å›¾ç‰‡
        
        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            
        Returns:
            é¢„å¤„ç†åçš„å›¾ç‰‡å¼ é‡
        """
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(image_path):
                raise FileNotFoundError(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            
            # åŠ è½½å›¾ç‰‡
            image = Image.open(image_path).convert('RGB')
            logger.info(f"âœ“ å›¾ç‰‡åŠ è½½æˆåŠŸ: {image_path}")
            logger.info(f"  åŸå§‹å°ºå¯¸: {image.size}")
            
            # é¢„å¤„ç†
            if self.transform:
                image_tensor = self.transform(image)
                # æ·»åŠ batchç»´åº¦
                image_tensor = image_tensor.unsqueeze(0)
                logger.info(f"  é¢„å¤„ç†åå½¢çŠ¶: {image_tensor.shape}")
                return image_tensor.to(self.device)
            else:
                raise ValueError("å›¾ç‰‡é¢„å¤„ç†å™¨æœªåˆå§‹åŒ–")
                
        except Exception as e:
            logger.error(f"å›¾ç‰‡åŠ è½½å¤±è´¥: {e}")
            raise
    
    def predict(self, image_input: Union[str, torch.Tensor]) -> Dict:
        """è¿›è¡Œæ¨ç†é¢„æµ‹
        
        Args:
            image_input: å›¾ç‰‡è·¯å¾„æˆ–é¢„å¤„ç†åçš„å¼ é‡
            
        Returns:
            åŒ…å«å„ç§é¢„æµ‹ç»“æœçš„å­—å…¸
        """
        try:
            # å¤„ç†è¾“å…¥
            if isinstance(image_input, str):
                image_tensor = self.load_image(image_input)
                image_path = image_input
            elif isinstance(image_input, torch.Tensor):
                image_tensor = image_input.to(self.device)
                image_path = "tensor_input"
            else:
                raise ValueError("ä¸æ”¯æŒçš„è¾“å…¥ç±»å‹")
            
            logger.info(f"å¼€å§‹æ¨ç†: {image_path}")
            
            # æ¨¡å‹æ¨ç†
            with torch.no_grad():
                outputs = self.model(image_tensor)
            
            # è§£æè¾“å‡º
            results = self.parse_outputs(outputs)
            
            logger.info("âœ“ æ¨ç†å®Œæˆ")
            return results
            
        except Exception as e:
            logger.error(f"æ¨ç†å¤±è´¥: {e}")
            raise
    
    def parse_outputs(self, outputs: Dict[str, torch.Tensor]) -> Dict:
        """è§£ææ¨¡å‹è¾“å‡º
        
        Args:
            outputs: æ¨¡å‹åŸå§‹è¾“å‡º
            
        Returns:
            è§£æåçš„é¢„æµ‹ç»“æœ
        """
        results = {
            'raw_outputs': {},
            'predictions': {},
            'probabilities': {},
            'top_predictions': {}
        }
        
        # 1. DeepFashionå±æ€§é¢„æµ‹
        if 'attr_logits' in outputs:
            attr_logits = outputs['attr_logits']
            attr_probs = torch.sigmoid(attr_logits)
            
            results['raw_outputs']['deepfashion_attrs'] = attr_logits.cpu()
            results['probabilities']['deepfashion_attrs'] = attr_probs.cpu()
            
            # è·å–é«˜ç½®ä¿¡åº¦çš„å±æ€§
            threshold = 0.5
            predicted_attrs = (attr_probs > threshold).cpu().numpy()[0]
            
            active_attrs = []
            for i, is_active in enumerate(predicted_attrs):
                if is_active and i < len(self.deepfashion_attrs):
                    confidence = attr_probs[0, i].item()
                    active_attrs.append({
                        'attribute': self.deepfashion_attrs[i],
                        'confidence': confidence
                    })
            
            # æŒ‰ç½®ä¿¡åº¦æ’åº
            active_attrs.sort(key=lambda x: x['confidence'], reverse=True)
            results['predictions']['deepfashion_attrs'] = active_attrs
            
            logger.info(f"  DeepFashionå±æ€§: {len(active_attrs)}ä¸ªæ¿€æ´»")
        
        # 2. Fabricçº¹ç†é¢„æµ‹
        if 'fabric_logits' in outputs:
            fabric_logits = outputs['fabric_logits']
            fabric_probs = F.softmax(fabric_logits, dim=1)
            
            results['raw_outputs']['fabric'] = fabric_logits.cpu()
            results['probabilities']['fabric'] = fabric_probs.cpu()
            
            # è·å–top-ké¢„æµ‹
            top_k = min(5, len(self.fabric_classes))
            top_probs, top_indices = torch.topk(fabric_probs, top_k, dim=1)
            
            fabric_predictions = []
            for i in range(top_k):
                idx = top_indices[0, i].item()
                prob = top_probs[0, i].item()
                if idx < len(self.fabric_classes):
                    fabric_predictions.append({
                        'class': self.fabric_classes[idx],
                        'confidence': prob
                    })
            
            results['predictions']['fabric'] = fabric_predictions[0] if fabric_predictions else None
            results['top_predictions']['fabric'] = fabric_predictions
            
            logger.info(f"  Fabricé¢„æµ‹: {fabric_predictions[0]['class'] if fabric_predictions else 'None'}")
        
        # 3. Fiberçº¤ç»´é¢„æµ‹
        if 'fiber_logits' in outputs:
            fiber_logits = outputs['fiber_logits']
            fiber_probs = F.softmax(fiber_logits, dim=1)
            
            results['raw_outputs']['fiber'] = fiber_logits.cpu()
            results['probabilities']['fiber'] = fiber_probs.cpu()
            
            # è·å–top-ké¢„æµ‹
            top_k = min(5, len(self.fiber_classes))
            top_probs, top_indices = torch.topk(fiber_probs, top_k, dim=1)
            
            fiber_predictions = []
            for i in range(top_k):
                idx = top_indices[0, i].item()
                prob = top_probs[0, i].item()
                if idx < len(self.fiber_classes):
                    fiber_predictions.append({
                        'class': self.fiber_classes[idx],
                        'confidence': prob
                    })
            
            results['predictions']['fiber'] = fiber_predictions[0] if fiber_predictions else None
            results['top_predictions']['fiber'] = fiber_predictions
            
            logger.info(f"  Fiberé¢„æµ‹: {fiber_predictions[0]['class'] if fiber_predictions else 'None'}")
        
        # 4. ç»Ÿä¸€çº¹ç†é¢„æµ‹
        if 'textile_logits' in outputs:
            textile_logits = outputs['textile_logits']
            textile_probs = F.softmax(textile_logits, dim=1)
            
            results['raw_outputs']['textile'] = textile_logits.cpu()
            results['probabilities']['textile'] = textile_probs.cpu()
            
            # è·å–æœ€é«˜ç½®ä¿¡åº¦é¢„æµ‹
            max_prob, max_idx = torch.max(textile_probs, dim=1)
            results['predictions']['textile'] = {
                'class_index': max_idx.item(),
                'confidence': max_prob.item()
            }
            
            logger.info(f"  Textileé¢„æµ‹: ç±»åˆ«{max_idx.item()}, ç½®ä¿¡åº¦{max_prob.item():.3f}")
        
        # 5. åˆ†å‰²é¢„æµ‹ï¼ˆå¦‚æœæœ‰ï¼‰
        if 'seg_logits' in outputs:
            seg_logits = outputs['seg_logits']
            seg_probs = torch.sigmoid(seg_logits)
            
            results['raw_outputs']['segmentation'] = seg_logits.cpu()
            results['probabilities']['segmentation'] = seg_probs.cpu()
            
            # ç”Ÿæˆåˆ†å‰²æ©ç 
            seg_mask = (seg_probs > 0.5).cpu().numpy()[0, 0]
            results['predictions']['segmentation'] = {
                'mask': seg_mask,
                'coverage': seg_mask.mean()
            }
            
            logger.info(f"  åˆ†å‰²é¢„æµ‹: è¦†ç›–ç‡{seg_mask.mean():.3f}")
        
        return results
    
    def predict_batch(self, image_paths: List[str]) -> List[Dict]:
        """æ‰¹é‡é¢„æµ‹
        
        Args:
            image_paths: å›¾ç‰‡è·¯å¾„åˆ—è¡¨
            
        Returns:
            é¢„æµ‹ç»“æœåˆ—è¡¨
        """
        results = []
        for image_path in image_paths:
            try:
                result = self.predict(image_path)
                result['image_path'] = image_path
                results.append(result)
            except Exception as e:
                logger.error(f"æ‰¹é‡é¢„æµ‹å¤±è´¥ {image_path}: {e}")
                results.append({
                    'image_path': image_path,
                    'error': str(e)
                })
        
        return results
    
    def format_results(self, results: Dict, detailed: bool = False) -> str:
        """æ ¼å¼åŒ–è¾“å‡ºç»“æœ
        
        Args:
            results: é¢„æµ‹ç»“æœå­—å…¸
            detailed: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
            
        Returns:
            æ ¼å¼åŒ–çš„ç»“æœå­—ç¬¦ä¸²
        """
        output = []
        output.append("=" * 60)
        output.append("å›¾ç‰‡åˆ†ç±»ç»“æœ")
        output.append("=" * 60)
        
        # DeepFashionå±æ€§ - æŒ‰ç±»åˆ«ç»„ç»‡æ˜¾ç¤º
        if 'deepfashion_attrs' in results['predictions']:
            attrs = results['predictions']['deepfashion_attrs']
            output.append(f"\nğŸ‘— æœè£…å±æ€§åˆ†æ:")
            
            # æŒ‰ç±»åˆ«ç»„ç»‡å±æ€§
            categorized_attrs = {}
            for attr in attrs:
                attr_name = attr['attribute']
                confidence = attr['confidence']
                
                # æ‰¾åˆ°å±æ€§å¯¹åº”çš„çœŸå®æ ‡ç­¾
                attr_idx = None
                for idx, name in self.DEEPFASHION_ATTRIBUTES.items():
                    if attr_name.endswith(f"_{idx}") or attr_name == name:
                        attr_idx = idx
                        break
                
                if attr_idx is not None:
                    real_name = self.DEEPFASHION_ATTRIBUTES[attr_idx]
                    
                    # æ‰¾åˆ°å±æ€§ç±»åˆ«
                    category = None
                    for cat_name, indices in self.ATTRIBUTE_CATEGORIES.items():
                        if attr_idx in indices:
                            category = cat_name
                            break
                    
                    if category:
                        if category not in categorized_attrs:
                            categorized_attrs[category] = []
                        categorized_attrs[category].append({
                            'name': real_name,
                            'confidence': confidence
                        })
            
            # æ˜¾ç¤ºå„ç±»åˆ«çš„å±æ€§
            category_names = {
                'pattern': 'ğŸ¨ å›¾æ¡ˆ',
                'sleeve': 'ğŸ‘• è¢–å‹', 
                'length': 'ğŸ“ é•¿åº¦',
                'neckline': 'ğŸ‘” é¢†å‹',
                'material': 'ğŸ§µ æè´¨',
                'fit': 'ğŸ“ ç‰ˆå‹'
            }
            
            for category, attrs_list in categorized_attrs.items():
                if attrs_list:
                    cat_name = category_names.get(category, category)
                    output.append(f"\n  {cat_name}:")
                    # æŒ‰ç½®ä¿¡åº¦æ’åºï¼Œæ˜¾ç¤ºå‰3ä¸ª
                    sorted_attrs = sorted(attrs_list, key=lambda x: x['confidence'], reverse=True)
                    for attr in sorted_attrs[:3]:
                        output.append(f"    â€¢ {attr['name']}: {attr['confidence']:.3f}")
            
            if not categorized_attrs:
                # å¦‚æœæ— æ³•åˆ†ç±»ï¼Œæ˜¾ç¤ºåŸå§‹ç»“æœ
                output.append("  æ£€æµ‹åˆ°çš„å±æ€§:")
                for attr in attrs[:5]:
                    output.append(f"    â€¢ {attr['attribute']}: {attr['confidence']:.3f}")
        
        # Fabricé¢„æµ‹
        if 'fabric' in results['predictions'] and results['predictions']['fabric']:
            fabric = results['predictions']['fabric']
            fabric_name = fabric['class']
            confidence = fabric['confidence']
            
            # æ·»åŠ é¢æ–™ç±»å‹çš„ä¸­æ–‡è¯´æ˜
            fabric_translations = {
                'lace': 'è•¾ä¸',
                'denim': 'ç‰›ä»”å¸ƒ',
                'cotton': 'æ£‰å¸ƒ',
                'silk': 'ä¸ç»¸',
                'wool': 'ç¾Šæ¯›',
                'polyester': 'èšé…¯çº¤ç»´',
                'leather': 'çš®é©',
                'chiffon': 'é›ªçºº',
                'knit': 'é’ˆç»‡ç‰©'
            }
            
            chinese_name = fabric_translations.get(fabric_name, fabric_name)
            output.append(f"\nğŸ§µ é¢æ–™ç±»å‹:")
            if chinese_name != fabric_name:
                output.append(f"  â€¢ {chinese_name} ({fabric_name}): {confidence:.3f}")
            else:
                output.append(f"  â€¢ {fabric_name}: {confidence:.3f}")
            
            if detailed and 'fabric' in results['top_predictions']:
                output.append("  å…¶ä»–å¯èƒ½çš„é¢æ–™:")
                for pred in results['top_predictions']['fabric'][:5]:
                    pred_chinese = fabric_translations.get(pred['class'], pred['class'])
                    if pred_chinese != pred['class']:
                        output.append(f"    - {pred_chinese} ({pred['class']}): {pred['confidence']:.3f}")
                    else:
                        output.append(f"    - {pred['class']}: {pred['confidence']:.3f}")
        
        # Fiberé¢„æµ‹
        if 'fiber' in results['predictions'] and results['predictions']['fiber']:
            fiber = results['predictions']['fiber']
            fiber_name = fiber['class']
            confidence = fiber['confidence']
            
            # æ·»åŠ çº¤ç»´ç±»å‹çš„ä¸­æ–‡è¯´æ˜
            fiber_translations = {
                'cotton': 'æ£‰çº¤ç»´',
                'wool': 'ç¾Šæ¯›çº¤ç»´',
                'silk': 'ä¸çº¤ç»´',
                'polyester': 'èšé…¯çº¤ç»´',
                'nylon': 'å°¼é¾™çº¤ç»´',
                'acrylic': 'è…ˆçº¶çº¤ç»´',
                'linen': 'äºšéº»çº¤ç»´',
                'rayon': 'äººé€ ä¸',
                'llama': 'ç¾Šé©¼æ¯›'
            }
            
            chinese_name = fiber_translations.get(fiber_name, fiber_name)
            output.append(f"\nğŸ§¶ çº¤ç»´ç±»å‹:")
            if chinese_name != fiber_name:
                output.append(f"  â€¢ {chinese_name} ({fiber_name}): {confidence:.3f}")
            else:
                output.append(f"  â€¢ {fiber_name}: {confidence:.3f}")
            
            if detailed and 'fiber' in results['top_predictions']:
                output.append("  å…¶ä»–å¯èƒ½çš„çº¤ç»´:")
                for pred in results['top_predictions']['fiber'][:5]:
                    pred_chinese = fiber_translations.get(pred['class'], pred['class'])
                    if pred_chinese != pred['class']:
                        output.append(f"    - {pred_chinese} ({pred['class']}): {pred['confidence']:.3f}")
                    else:
                        output.append(f"    - {pred['class']}: {pred['confidence']:.3f}")
        
        # åˆ†å‰²ç»“æœ
        if 'segmentation' in results['predictions']:
            seg = results['predictions']['segmentation']
            output.append(f"\nâœ‚ï¸ åˆ†å‰²ç»“æœ:")
            output.append(f"  â€¢ è¦†ç›–ç‡: {seg['coverage']:.3f}")
        
        # æ™ºèƒ½æ€»ç»“
        output.append(f"\nğŸ¯ æ™ºèƒ½åˆ†ææ€»ç»“:")
        summary_parts = []
        
        # ä»å±æ€§ä¸­æå–å…³é”®ä¿¡æ¯
        if 'deepfashion_attrs' in results['predictions']:
            attrs = results['predictions']['deepfashion_attrs']
            if attrs:
                # æ‰¾åˆ°æœ€é«˜ç½®ä¿¡åº¦çš„å±æ€§
                top_attr = max(attrs, key=lambda x: x['confidence'])
                attr_name = top_attr['attribute']
                
                # å°è¯•è§£æå±æ€§å
                for idx, name in self.DEEPFASHION_ATTRIBUTES.items():
                    if attr_name.endswith(f"_{idx}"):
                        summary_parts.append(f"ä¸»è¦ç‰¹å¾ä¸º{name}")
                        break
        
        # æ·»åŠ é¢æ–™ä¿¡æ¯
        if 'fabric' in results['predictions'] and results['predictions']['fabric']:
            fabric = results['predictions']['fabric']
            fabric_translations = {
                'lace': 'è•¾ä¸', 'denim': 'ç‰›ä»”å¸ƒ', 'cotton': 'æ£‰å¸ƒ', 'silk': 'ä¸ç»¸',
                'wool': 'ç¾Šæ¯›', 'polyester': 'èšé…¯çº¤ç»´', 'leather': 'çš®é©', 'chiffon': 'é›ªçºº'
            }
            fabric_chinese = fabric_translations.get(fabric['class'], fabric['class'])
            summary_parts.append(f"é¢æ–™ä¸º{fabric_chinese}")
        
        # æ·»åŠ çº¤ç»´ä¿¡æ¯
        if 'fiber' in results['predictions'] and results['predictions']['fiber']:
            fiber = results['predictions']['fiber']
            fiber_translations = {
                'cotton': 'æ£‰çº¤ç»´', 'wool': 'ç¾Šæ¯›çº¤ç»´', 'silk': 'ä¸çº¤ç»´',
                'polyester': 'èšé…¯çº¤ç»´', 'llama': 'ç¾Šé©¼æ¯›'
            }
            fiber_chinese = fiber_translations.get(fiber['class'], fiber['class'])
            summary_parts.append(f"çº¤ç»´ä¸º{fiber_chinese}")
        
        if summary_parts:
            output.append(f"  è¿™æ˜¯ä¸€ä»¶{', '.join(summary_parts)}çš„æœè£…ã€‚")
        else:
            output.append("  æœªèƒ½è¯†åˆ«å‡ºæ˜ç¡®çš„æœè£…ç‰¹å¾ã€‚")
        
        output.append("=" * 60)
        return "\n".join(output)


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºæ¨ç†åŠŸèƒ½"""
    import argparse
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='æœè£…å›¾ç‰‡æ¨ç†è„šæœ¬')
    parser.add_argument('--model_path', type=str, 
                       default="smart_mixed_checkpoints/best_model.pth",
                       help='è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„')
    parser.add_argument('--image_path', type=str,
                       help='è¦æ¨ç†çš„å›¾ç‰‡è·¯å¾„')
    parser.add_argument('--output_detail', action='store_true',
                       help='è¾“å‡ºè¯¦ç»†çš„é¢„æµ‹ç»“æœ')
    
    args = parser.parse_args()
    
    logger.info("å¼€å§‹å›¾ç‰‡æ¨ç†æ¼”ç¤º...")
    
    # é…ç½®
    model_path = args.model_path
    test_images = []
    
    # å¦‚æœæŒ‡å®šäº†å›¾ç‰‡è·¯å¾„ï¼Œæ·»åŠ åˆ°æµ‹è¯•åˆ—è¡¨
    if args.image_path:
        test_images.append(args.image_path)
    else:
        # é»˜è®¤æµ‹è¯•å›¾ç‰‡ï¼ˆå¦‚æœæ²¡æœ‰æŒ‡å®šï¼‰
        test_images = [
            # å¯ä»¥æ·»åŠ æµ‹è¯•å›¾ç‰‡è·¯å¾„
            # "/path/to/test/image1.jpg",
            # "/path/to/test/image2.jpg",
        ]
    
    try:
        # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
        if not os.path.exists(model_path):
            logger.warning(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            logger.info("è¯·å…ˆè®­ç»ƒæ¨¡å‹æˆ–æä¾›æ­£ç¡®çš„æ¨¡å‹è·¯å¾„")
            return
        
        # åˆ›å»ºæ¨ç†å™¨
        inferencer = FashionInference(model_path)
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæµ‹è¯•å›¾ç‰‡ï¼Œå°è¯•ä»æ•°æ®é›†ä¸­æ‰¾ä¸€äº›
        if not test_images:
            logger.info("æ­£åœ¨å¯»æ‰¾æµ‹è¯•å›¾ç‰‡...")
            
            # ä»fabricæ•°æ®é›†ä¸­æ‰¾ä¸€äº›å›¾ç‰‡
            fabric_dir = "/home/cv_model/fabric/train"
            if os.path.exists(fabric_dir):
                for class_dir in os.listdir(fabric_dir)[:3]:  # å–å‰3ä¸ªç±»åˆ«
                    class_path = os.path.join(fabric_dir, class_dir)
                    if os.path.isdir(class_path):
                        images = [f for f in os.listdir(class_path) 
                                if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
                        if images:
                            test_images.append(os.path.join(class_path, images[0]))
            
            # ä»fiberæ•°æ®é›†ä¸­æ‰¾ä¸€äº›å›¾ç‰‡
            fiber_dir = "/home/cv_model/fiber/train"
            if os.path.exists(fiber_dir):
                for class_dir in os.listdir(fiber_dir)[:2]:  # å–å‰2ä¸ªç±»åˆ«
                    class_path = os.path.join(fiber_dir, class_dir)
                    if os.path.isdir(class_path):
                        images = [f for f in os.listdir(class_path) 
                                if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
                        if images:
                            test_images.append(os.path.join(class_path, images[0]))
        
        if not test_images:
            logger.warning("æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•å›¾ç‰‡")
            logger.info("è¯·åœ¨ä»£ç ä¸­æŒ‡å®šæµ‹è¯•å›¾ç‰‡è·¯å¾„æˆ–ç¡®ä¿æ•°æ®é›†å­˜åœ¨")
            return
        
        logger.info(f"æ‰¾åˆ° {len(test_images)} å¼ æµ‹è¯•å›¾ç‰‡")
        
        # è¿›è¡Œæ¨ç†
        for i, image_path in enumerate(test_images):
            logger.info(f"\nå¤„ç†å›¾ç‰‡ {i+1}/{len(test_images)}: {image_path}")
            
            try:
                # æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if not os.path.exists(image_path):
                    logger.error(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
                    continue
                
                # å•å¼ å›¾ç‰‡æ¨ç†
                results = inferencer.predict(image_path)
                
                # æ ¼å¼åŒ–å¹¶æ˜¾ç¤ºç»“æœ
                detailed = args.output_detail if 'args' in locals() else True
                formatted_results = inferencer.format_results(results, detailed=detailed)
                print(formatted_results)
                
            except Exception as e:
                logger.error(f"å›¾ç‰‡ {image_path} æ¨ç†å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        
        logger.info("\nâœ“ æ¨ç†æ¼”ç¤ºå®Œæˆ")
        
    except Exception as e:
        logger.error(f"æ¨ç†æ¼”ç¤ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
