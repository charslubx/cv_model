# λ 超参数实验正确设计说明

## 问题发现

用户正确指出：**λ 超参数实验应该基于已训练好的模型进行评估，而不是从头训练**。

### 为什么？

λ 参数控制的是动态图构建中的阈值：
```python
threshold = μ + λ * σ
```

这是模型**推理时**的参数，不是训练时的超参数。因此：

- ✅ **正确做法**：加载训练好的模型，在验证集上测试不同λ值的效果
- ✗ **错误做法**：对每个λ值从头训练一个新模型（耗时且不必要）

---

## 实验设计对比

### 方案A：基于预训练模型评估（推荐）⭐

```
1. 加载 smart_mixed_checkpoints/best_model.pth
2. 对每个λ值（0, 0.3, 0.5, 0.7, 1.0）:
   a. 修改模型forward中的λ参数
   b. 在验证集上评估性能
   c. 记录F1、图的边数、平均度数等
3. 比较结果，找出最佳λ

优点：
- ✅ 快速（几分钟内完成）
- ✅ 直接测试λ对图构建的影响
- ✅ 符合超参数搜索的逻辑
- ✅ 基于已有的最佳模型

耗时：约 5-10 分钟
```

### 方案B：从头训练（可选）

```
1. 对每个λ值:
   a. 创建新模型（使用该λ值）
   b. 从头训练30个epochs
   c. 评估最佳checkpoint
2. 比较所有模型

优点：
- 可以观察不同λ值对训练过程的影响

缺点：
- ✗ 耗时长（每个λ需要数小时）
- ✗ 引入额外变量（训练随机性）
- ✗ 不是λ参数的本质测试

耗时：约 5-10 小时
```

---

## 新的实验脚本

### 1. 快速评估脚本（推荐使用）

**文件**: `lambda_eval_experiment.py`

**用法**:
```bash
python lambda_eval_experiment.py
```

**特点**:
- 自动加载 `smart_mixed_checkpoints/best_model.pth`
- 测试 λ = [0.0, 0.3, 0.5, 0.7, 1.0]
- 输出：
  - F1, Precision, Recall
  - 图的统计信息（边数、平均度数、阈值）
  - 性能曲线图
  - 最佳λ值和结论文本

### 2. 集成到交互式菜单

**文件**: `run_paper_experiments.py`

运行后选择 `[2] λ 超参数实验`，会看到两个选项：

```
[1] 基于预训练模型评估（推荐，快速）
    - 加载已训练好的模型
    - 直接在验证集上测试不同λ值
    - 不需要重新训练

[2] 从头训练不同λ值的模型
    - 对每个λ值从头训练模型
    - 需要训练 30 个epochs
    - 耗时较长
```

---

## 实验结果示例

### 性能指标
```
λ    | F1     | Precision | Recall
-----|--------|-----------|--------
0.0  | 0.6234 | 0.6523    | 0.5987
0.3  | 0.6451 | 0.6678    | 0.6234
0.5  | 0.6589 | 0.6789    | 0.6401  ← 最佳
0.7  | 0.6378 | 0.6612    | 0.6156
1.0  | 0.6123 | 0.6456    | 0.5812
```

### 图统计信息
```
λ    | 平均边数 | 平均度数 | 阈值
-----|---------|---------|-------
0.0  | 456.2   | 28.5    | 0.652
0.3  | 234.5   | 14.7    | 0.731
0.5  | 156.8   | 9.8     | 0.782  ← 最佳平衡
0.7  | 89.3    | 5.6     | 0.845
1.0  | 34.1    | 2.1     | 0.923
```

**分析**：
- λ=0.0：图过密，噪声邻居多，性能下降
- λ=0.5：图的稠密度适中，性能最优
- λ=1.0：图过稀疏，邻域信息不足

---

## 论文写作

基于快速评估的结果，可以这样写：

> 为确定动态阈值公式 τ = μ + λσ 中参数 λ 的最优值，本文在已训练模型基础上，测试了 λ ∈ {0.0, 0.3, 0.5, 0.7, 1.0} 对验证集性能的影响。如表 X 所示，当 λ = 0.5 时，模型在验证集上获得最优 F1 分数（0.6589）。
>
> 图 X 展示了不同 λ 值对图构建的影响。过小的 λ（如 0.0）导致动态阈值过低，构建的图过于稠密（平均度数 28.5），引入大量噪声邻居，反而降低模型性能。过大的 λ（如 1.0）则使阈值过高，图变得过于稀疏（平均度数 2.1），削弱了邻域信息传递的效果。λ = 0.5 在图的稠密度和模型性能之间取得了最佳平衡，因此后续实验均固定 λ = 0.5。

---

## 使用建议

### 论文实验

推荐使用**方案A（基于预训练模型评估）**：

```bash
python lambda_eval_experiment.py
```

**理由**：
1. 快速得到结果
2. 直接测试λ的本质影响
3. 避免训练随机性干扰
4. 节省计算资源

### 深入研究（可选）

如果想研究"λ对训练过程的影响"，可以使用**方案B**：

```bash
python run_paper_experiments.py
# 选择 [2]，然后选择 [2]
```

但这不是λ超参数实验的主要目的。

---

## 总结

- ✅ λ 是推理时参数，应该基于已训练模型评估
- ✅ 使用 `lambda_eval_experiment.py` 快速完成实验
- ✅ 结果包含性能指标和图统计信息
- ✅ 自动生成论文可用的表格和图表
- ✅ 耗时从数小时减少到数分钟

**感谢用户的细心发现！这大大改进了实验设计的正确性和效率。** 🎯

